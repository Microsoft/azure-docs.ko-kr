---
title: 음성 텍스트 변환에 대한 질문과 대답
titleSuffix: Azure Cognitive Services
description: 음성 텍스트 서비스에 대 한 자주 묻는 질문에 대 한 답을 가져옵니다.
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 12/4/2019
ms.author: panosper
ms.openlocfilehash: a96a3de7c8ad309986417e21a13d5e18f56cbd24
ms.sourcegitcommit: 014e916305e0225512f040543366711e466a9495
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/14/2020
ms.locfileid: "75934120"
---
# <a name="speech-to-text-frequently-asked-questions"></a>음성 텍스트 변환에 대한 질문과 대답

이 FAQ에서 질문에 대한 답변을 찾을 수 없는 경우 [다른 지원 옵션](support.md)을 확인하세요.

## <a name="general"></a>일반

**Q: 기준 음성 텍스트 변환 모델과 사용자 지정 음성 텍스트 변환 모델의 차이는 무엇인가요?**

**A:** 기준 모델은 Microsoft가 소유한 데이터를 사용하여 학습이 되었으며 클라우드에 이미 배포되어 있습니다. 사용자 지정 모델을 사용하면 특정한 주변 소음이나 언어가 있는 특정 환경에 적합하게 모델을 적응시킬 수 있습니다. 공장 현장, 자동차 또는 소음이 많은 거리에 적응형 음향 모델이 필요합니다. 생물학, 물리학, 방사선, 제품 이름 등의 주제와 사용자 지정 약어에 적응형 언어 모델이 필요합니다.

**Q: 기준 모델을 사용하려면 무엇부터 시작해야 하나요?**

**A**: 먼저 [구독 키](get-started.md)를 확보합니다. 미리 배포된 기준 모델을 REST 방식으로 호출하려면 [REST API](rest-apis.md)를 참조하세요. WebSocket을 사용하려면 [SDK를 다운로드](speech-sdk.md)합니다.

**Q: 사용자 지정 음성 모델을 항상 작성해야 하나요?**

**A**: 아니요. 애플리케이션에서 일반적인 일상 언어를 사용하는 경우라면 모델을 사용자 지정할 필요가 없습니다. 배경 소음이 거의 또는 전혀 없는 환경에서 애플리케이션을 사용하는 경우 모델을 사용자 지정할 필요가 없습니다.

포털에서 기준 모델 및 사용자 지정 모델을 배포하고 그에 대한 정확도 테스트를 실행할 수 있습니다. 이러한 기능을 사용하여 기준 모델과 사용자 지정 모델의 정확성을 측정할 수 있습니다.

**Q: 데이터 세트나 모델의 처리가 완료되면 어떻게 알 수 있나요?**

**A**: 현재는, 테이블에 있는 모델이나 데이터 세트의 상태만 알면 됩니다. 처리가 완료되면 **성공** 상태가 됩니다.

**Q: 모델을 둘 이상 만들 수 있나요?**

**A**: 컬렉션에 포함할 수 있는 모델 수에는 제한이 없습니다.

**Q: 잘못 된 것으로 인식 했습니다. 진행 중인 데이터 가져오기 또는 모델 만들기를 취소 어떻게 할까요?**

**A**: 현재는 음향 적응 또는 언어 적응 프로세스를 롤백할 수 없습니다. 종료 상태에 있을 때 가져온 데이터와 모델을 삭제할 수 있습니다.

**Q: 검색 및 받아쓰기 모델과 대화형 모델의 차이는 무엇인가요?**

**A**: Speech Service에서 둘 이상의 기준 모델 중에서 선택할 수 있습니다. 대화형 모델은 대화 스타일로 통용되는 음성을 인식하는 데 유용합니다. 이 모델은 전화 통화를 기록하는 데 적합합니다. 검색 및 받아쓰기 모델은 음성 트리거 앱에 적합합니다. 유니버설 모델이 두 시나리오를 모두 해결하기 위한 새 모델입니다. 유니버설 모델의 품질은 현재 대부분의 로캘에서 대화형 모델의 품질 수준 이상입니다.

**Q: 기존 모델(모델 스택)을 업데이트할 수 있나요?**

**A**: 기존 모델을 업데이트할 수 없습니다. 해결 방안은 이전 데이터 세트를 새 데이터 세트와 결합하여 다시 적응시키는 것입니다.

이전 데이터 세트 및 새 데이터 세트를 단일 .zip 파일(음향 데이터) 또는 .txt 파일(언어 데이터)에 결합해야 합니다. 적응이 완료된 후에는 새로 업데이트된 모델을 다시 배포하여 새 엔드포인트를 확보해야 합니다.

**Q: 새 버전의 기준을 사용할 수 있는 경우 배포가 자동으로 업데이트 되나요?**

**A**: 배포는 자동으로 업데이트되지 않습니다.

기준 V1.0의 모델을 적응시키고 배포하면 배포는 원래 상태를 유지합니다. 고객은 새 버전의 기준선을 사용 하 고 다시 배포 하는 readapt 배포 된 모델을 서비스 해제할 수 있습니다.

**Q: 내 모델을 다운로드하여 로컬로 실행할 수 있나요?**

**A**: 모델을 다운로드하여 로컬로 실행할 수 없습니다.

**Q: 내 요청이 기록되나요?**

**A**: 배포를 만들 때 추적을 해제하는 옵션을 사용할 수 있습니다. 이 경우 오디오 또는 전사는 기록되지 않습니다. 그렇지 않으면 일반적으로 Azure에서 보안 스토리지에 요청이 기록됩니다.

**Q: 내 요청이 제한되나요?**

**A**: REST API의 경우 5초당 25개 요청으로 제한됩니다. 자세한 내용은 [음성을 텍스트로 변환](speech-to-text.md)에 대한 페이지에서 찾을 수 있습니다.

**Q: 이중 채널 오디오에 대 한 요금은 어떻게 청구 되나요?**

**A**: 각 채널을 별도로 제출 하는 경우 (각 채널은 자체 파일에) 각 파일의 기간에 대해 요금이 청구 됩니다. 각 채널이 함께 멀티플렉싱 단일 파일을 제출 하면 단일 파일의 기간에 대 한 요금이 청구 됩니다. 가격 책정에 대 한 자세한 내용은 [Azure Cognitive Services 가격 책정 페이지](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)를 참조 하세요.

> [!IMPORTANT]
> 그 밖의 개인 정보 보호 문제로 인해 Custom Speech Service를 사용할 수 없는 경우에는 지원 채널 중 한 곳에 문의하세요.

## <a name="increasing-concurrency"></a>동시성 증대

**Q: 포털에 제공되는 모델보다 배포된 모델에 대해 더 높은 동시성이 필요하면 어떻게 해야 하나요?**

**A**: 모델은 20개씩 증분하는 동시 요청으로 강화할 수 있습니다.

필요한 정보를 사용 하 여 [Azure 지원 포털](https://ms.portal.azure.com/#blade/Microsoft_Azure_Support/HelpAndSupportBlade/overview)에서 지원 요청을 만듭니다. [지원 페이지](support.md)에 언급 된 공개 채널 (GitHub, stackoverflow, ...) 중 하나에 정보를 게시 하지 마십시오.

***사용자 지정 모델***에 대 한 동시성을 늘리려면 다음 정보가 필요 합니다.

- 모델을 배포 하는 영역입니다.
- 배포 된 모델의 엔드포인트 ID:
  - [Custom Speech 포털](https://aka.ms/customspeech)에서 가져왔습니다.
  - 로그인 (필요한 경우)
  - 프로젝트 및 배포를 선택 합니다.
  - 에 대해 동시성이 증가 해야 하는 엔드포인트을 선택 합니다.
  - `Endpoint ID`를 복사 합니다.

***기본 모델***의 동시성을 늘리려면 다음 정보가 필요 합니다.

- 서비스의 지역입니다.

그리고 다음 중 하나입니다.

- 구독에 대 한 액세스 토큰 ( [여기](https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#how-to-get-an-access-token)참조)

또는

- 구독에 대 한 리소스 ID:
  - [Azure Portal](https://portal.azure.com)로 이동 합니다.
  - 검색 상자에서 `Cognitive Services`를 선택 합니다.
  - 표시 된 서비스에서 동시성을 증가 시킬 음성 서비스를 선택 합니다.
  - 이 서비스에 대 한 `Properties`를 표시 합니다.
  - 전체 `Resource ID`를 복사 합니다.

## <a name="importing-data"></a>데이터 가져오기

**Q: 데이터 세트의 크기 제한은 얼마나 되며 제한되는 이유는 무엇인가요?**

**A**: 데이터 세트의 현재 제한은 2GB입니다. 이러한 제한은 HTTP 업로드용 파일 크기가 제한되기 때문에 발생합니다.

**Q: 더 큰 텍스트 파일을 업로드할 수 있도록 내 텍스트 파일을 zip할 수 있나요?**

**A**: 아니요. 현재는 압축되지 않은 텍스트 파일만 허용됩니다.

**Q: 데이터 보고서에 길이 발언 실패 했다는 메시지가 표시 됩니다. 문제가 무엇 인가요?**

**A**: 파일에 발언을 100% 업로드하지 못하는 것은 문제가 아닙니다. 음향 데이터 세트나 언어 데이터 세트에서 대부분의 음성을(예: 95% 초과) 가져온 경우에는 데이터 세트를 사용할 수 있습니다. 단, 음성이 실패한 이유를 이해하고 문제 해결을 시도하는 것이 좋습니다. 가장 일반적인 문제(예: 서식 오류)는 쉽게 해결할 수 있습니다.

## <a name="creating-an-acoustic-model"></a>음향 모델 만들기

**Q: 음향 데이터가 얼마나 많이 필요한가요?**

**A**: 30분에서 1시간 분량의 음향 데이터로 시작하는 것이 좋습니다.

**Q: 어떤 데이터를 수집해야 하나요?**

**A**: 애플리케이션 시나리오 및 사용 사례와 최대한 가까운 데이터를 수집하세요. 데이터 컬렉션은 디바이스, 환경 및 화자 유형과 관련하여 대상 애플리케이션 및 사용자와 일치해야 합니다. 일반적으로 최대한 광범위한 화자의 데이터를 수집해야 합니다.

**Q: 음향 데이터는 어떻게 수집해야 하나요?**

**A**: 독립 실행형 데이터 수집 애플리케이션을 만들거나 기존 오디오 녹음 소프트웨어를 사용하면 됩니다. 오디오 데이터를 기록한 다음, 해당 데이터를 사용하는 버전의 애플리케이션을 만들 수도 있습니다.

**Q: 적응 데이터를 직접 전사해야 하나요?**

**A**: 예. 직접 전사하거나 전문적인 전사 서비스를 사용할 수 있습니다. 크라우드소싱을 사용하거나 전사를 직접 수행해야 하는 사용자도 있고 전사 전문가를 선호하는 사용자도 있습니다.

## <a name="accuracy-testing"></a>정확도 테스트

**Q: 사용자 지정 언어 모델을 사용하여 내 사용자 지정 음향 모델의 오프라인 테스트 수행할 수 있나요?**

**A**: 예, 오프라인 테스트를 설정할 때 드롭다운 메뉴에서 사용자 지정 언어 모델을 선택하기만 하면 됩니다.

**Q: 사용자 지정 음향 모델을 사용하여 내 사용자 지정 언어 모델의 오프라인 테스트 수행할 수 있나요?**

**A**: 예, 오프라인 테스트를 설정할 때 드롭다운 메뉴에서 사용자 지정 음향 모델을 선택하기만 하면 됩니다.

**Q: WER(단어 오류율)이란 무엇이고 어떻게 계산되나요?**

**A**: WER은 음성 인식을 위한 평가 메트릭입니다. WER은 삽입, 삭제 및 대체를 포함하는 총 오류 수를 참조 전사에 포함된 총 단어 수로 나누어 계산됩니다. 자세한 내용은 [단어 오류율](https://en.wikipedia.org/wiki/Word_error_rate)을 참조하세요.

**Q: 정확도 테스트의 결과가 좋은지 여부를 어떻게 판단하나요?**

**A**: 결과에는 기준 모델과 사용자 지정 모델 간의 비교가 표시됩니다. 사용자 지정이 빛을 발하려면 기준 모델보다 우수해야 합니다.

**Q: 기준 모델의 WER을 확인하여 개선되었는지 알아보려면 어떻게 해야 하나요?**

**A**: 오프라인 테스트 결과에는 기준 모델의 정확도와 사용자 지정 모델의 정확도 및 기준 모델보다 개선된 측면이 표시됩니다.

## <a name="creating-a-language-model"></a>언어 모델 만들기

**Q: 얼마나 많은 텍스트 데이터를 업로드해야 하나요?**

**A**: 애플리케이션에 사용된 어휘와 문구가 시작 언어 모델과 얼마나 다른지에 따라 달라집니다. 모든 새 단어에 대해 예제를 가능한 한 많이 제공하는 것이 유용합니다. 애플리케이션에서 사용되는 일반적인 문구의 경우 언어 데이터의 문구도 포함하면 유용합니다. 이러한 단어도 경청하도록 시스템에 지시하기 때문입니다. 언어 데이터 세트에 적어도 100개, 일반적으로 수백 개 또는 그 이상의 발언이 있는 것이 일반적입니다. 또한 일부 유형의 쿼리가 다른 쿼리 유형보다 일반적일 것으로 예상되는 경우 데이터 세트에 일반적인 쿼리의 복사본을 여러 개 삽입할 수 있습니다.

**Q: 단어 목록을 업로드할 수 있나요?**

**A**: 단어 목록을 업로드하면 단어가 어휘에 추가되지만 시스템에서 단어가 일반적으로 사용되는 방식이 학습되지는 않습니다. 전체 또는 부분 음성(사용자가 말하려는 문장이나 문구)을 제공하면 언어 모델이 새 단어를 학습하고 이 단어가 어떻게 사용되는지 학습할 수 있습니다. 사용자 지정 언어 모델은 시스템에 새 단어를 추가하는 것뿐만 아니라 애플리케이션에서 알려진 단어가 나타날 가능성을 조정하는 데에도 적합합니다. 전체 음성을 제공하면 시스템 학습 성능이 좋아집니다.

## <a name="tenant-model-custom-speech-with-office-365-data"></a>테넌트 모델 (Office 365 데이터를 사용 하는 Custom Speech)

**Q: 테넌트 모델에 포함 되는 정보와 생성 방법**

**A:** 테넌트 모델은 조직의 모든 사용자가 볼 수 있는 [공개 그룹](https://support.office.com/article/learn-about-office-365-groups-b565caa1-5c40-40ef-9915-60fdb2d97fa2) 메일 및 문서를 사용 하 여 빌드됩니다.

**Q: 테넌트 모델에서 어떤 음성 환경이 개선 되나요?**

**A:** 테넌트 모델을 사용 하도록 설정 하 고 만들고 게시 하면, 음성 서비스를 사용 하 여 빌드된 모든 엔터프라이즈 응용 프로그램에 대 한 인식을 개선 하는 데 사용 됩니다. 또한 엔터프라이즈에 대 한 멤버 자격을 나타내는 사용자 AAD 토큰을 전달 합니다.

음성 서비스 응용 프로그램에 대 한 테넌트 모델을 만들 때 받아쓰기 및 PowerPoint 캡션 등 Office 365에 내장 된 음성 환경은 변경 되지 않습니다.

## <a name="next-steps"></a>다음 단계

- [문제 해결](troubleshooting.md)
- [릴리스 정보](releasenotes.md)
