---
title: Custom Voice 만들기 - Speech Service
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되면 Custom Voice 포털로 이동합니다. Custom Voice 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘 및 성별 속성을 공유해야 합니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 541448f08e4ce9961d34063dcc225bf89d969a73
ms.sourcegitcommit: f28ebb95ae9aaaff3f87d8388a09b41e0b3445b5
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/30/2021
ms.locfileid: "101703374"
---
# <a name="create-a-custom-voice"></a>사용자 지정 음성 만들기

[Custom Voice용 데이터 준비](how-to-custom-voice-prepare-data.md)에서는 사용자 지정 음성을 교육하는 데 사용할 수 있는 다양한 데이터 유형과 다양한 형식 요구 사항에 대해 설명했습니다. 데이터를 준비했으면 [Custom Voice 포털](https://aka.ms/custom-voice-portal) 또는 Custom Voice 교육 API를 통해 업로드를 시작할 수 있습니다. 여기에서는 포털을 통해 사용자 지정 음성을 훈련하는 단계를 설명합니다.

> [!NOTE]
> 이 페이지에서는 [Custom Voice 시작](how-to-custom-voice.md) 및 [Custom Voice용 데이터 준비](how-to-custom-voice-prepare-data.md)를 읽고 Custom Voice 프로젝트를 만들었다고 가정합니다.

사용자 지정 음성: [사용자 지정 언어](language-support.md#customization)에 지원되는 언어를 확인합니다.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가 되면 [Custom Voice 포털](https://aka.ms/custom-voice-portal)로 이동합니다. Custom Voice 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘 및 성별 속성을 공유해야 합니다. 예를 들어, 영국식 영어로 오디오를 녹음한 경우 `en-GB`를 선택합니다.

**데이터** 탭으로 이동하여 **데이터 업로드** 를 클릭합니다. 마법사에서 준비한 것과 일치하는 올바른 데이터 유형을 선택합니다.

업로드하는 각 데이터 세트는 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 데이터를 업로드하기 전에 올바른 형식을 지정하는 것이 중요합니다. 이렇게 하면 Custom Voice 서비스에서 데이터를 정확하게 처리할 수 있습니다. [Custom Voice용 데이터 준비](how-to-custom-voice-prepare-data.md)로 이동하여 데이터 형식이 올바른지 확인합니다.

> [!NOTE]
> 무료 구독(F0) 사용자는 두 개의 데이터 세트를 동시에 업로드할 수 있습니다. 표준 구독(S0) 사용자는 다섯 개의 데이터 세트를 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 구독당 가져올 수 있는 최대 데이터 세트 수는 무료 구독(F0) 사용자의 경우 10개의 .zip 파일이고 표준 구독(S0) 사용자의 경우 500개입니다.

업로드 단추를 누르면 데이터 세트의 유효성이 자동으로 검사됩니다. 데이터 유효성 검사에는 오디오 파일의 파일 형식, 크기 및 샘플링 레이트를 확인하는 일련의 검사가 포함됩니다. 오류가 있으면 이를 수정하고 다시 제출합니다. 데이터 가져오기 요청이 시작되면 방금 업로드한 데이터 세트에 해당하는 항목이 데이터 테이블에 표시됩니다.

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여줍니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 데이터 세트를 수신하여 처리하고 있습니다. |
| 성공 | 데이터 세트의 유효성이 검사되었으며 음성 모델 빌드에 사용할 준비가 되었습니다. |
| 실패 | 파일 오류, 데이터 문제 또는 네트워크 문제와 같은 여러 이유로 인해 처리 중에 데이터 세트가 실패했습니다. |

유효성 검사가 완료되면 **발화** 열의 각 데이터 세트에 대해 일치하는 발화의 총 개수를 확인할 수 있습니다. 선택한 데이터 유형에 긴 오디오 세분화가 필요한 경우 이 열은 대화 내용 기록을 기반으로 또는 음성 대화 내용 기록 서비스를 통해 세분화된 발화만 반영합니다. 성공적으로 가져온 발화의 세부 결과와 해당 매핑 기록을 보려면 유효성이 검사된 데이터 세트를 추가로 다운로드할 수 있습니다. 힌트: 긴 오디오 세분화는 데이터 처리를 완료하는 데 1시간 넘게 걸릴 수 있습니다.

데이터 세부 정보 보기에서 각 데이터 세트의 발음 점수와 잡음 수준을 추가로 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

> [!NOTE]
> 사용자 지정 신경망 음성을 사용하는 경우 **성우** 탭에서 성우를 등록해야 합니다. 녹음 스크립트를 준비할 때, 아래 문장을 포함하여 TTS 음성 모델을 만들고 합성 음성을 생성하기 위해 성우의 음성 데이터를 사용하는 것에 대해 해당 성우의 인정을 받아야 합니다. "나[성 및 이름]는 내 음성의 합성 버전을 만들고 사용하기 위해 [회사 이름]에서 내 음성 녹음이 사용된다는 것을 알고 있습니다."
이 문장은 학습 데이터 세트가 동의한 사람에 의해 녹음되었는지 확인하는 데 사용됩니다. [여기에서 어떻게 데이터가 처리되고 성우 확인이 수행되는지 자세히 알아보세요](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext). 

## <a name="build-your-custom-voice-model"></a>사용자 지정 음성 모델 빌드

유효성이 검사된 데이터 세트는 사용자 지정 음성 모델을 빌드하는 데 사용할 수 있습니다.

1.  **텍스트 음성 변환 > Custom Voice> [프로젝트 이름]> 모델** 로 이동합니다.

2.  **모델 학습** 을 클릭합니다.

3.  그 다음, 이 모델을 식별하는 데 도움이 되는 **이름** 과 **설명** 을 입력합니다.

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 몇 가지 문장 부호 문자(예: -, \_ 및 (', '))만 허용됩니다. 음성 모델마다 다른 이름을 사용합니다.

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 세트의 이름을 기록하는 것입니다.

4.  **학습 데이터 선택** 페이지에서 학습에 사용할 데이터 세트를 하나 또는 여러 개 선택합니다. 제출하기 전에 발화 수를 확인합니다. "적응" 학습 방법을 통해 en-US 및 zh-CN 음성 모델을 여러 번 말하여 시작할 수 있습니다. 다른 로캘의 경우 "통계 파라메트릭"및 "연속" 학습 방법을 포함한 표준 계층을 사용하여 음성을 학습할 수 있도록 2,000개 넘는 발화를 선택해야 하며, 사용자 지정 신경망 음성을 학습하기 위해 300개 넘는 발화를 선택해야 합니다. 

    > [!NOTE]
    > 중복된 오디오 이름은 학습에서 제거됩니다. 선택한 데이터 세트에 여러 .zip 파일에 동일한 오디오 이름이 포함되지 않도록 합니다.

    > [!TIP]
    > 우수한 품질의 결과를 위해서는 동일한 화자의 데이터 세트를 사용해야 합니다. 학습 방법마다 학습 데이터 크기가 다릅니다. "통계 파라메트릭" 방법을 사용하여 모델을 학습하려면 최소 2000개의 고유한 발언이 필요합니다. "연속" 방법의 경우 6000개의 발언이 필요하며, "신경망"의 경우 최소 데이터 크기 요구 사항은 300개의 발언입니다.

5. 다음 단계에서 **학습 방법** 을 선택합니다. 

    > [!NOTE]
    > 신경망 음성을 학습시키려면, 자신의 음성 데이터를 사용자 지정 음성 모델을 학습시키는 데 사용하는 것을 인정하는 성우가 제공한 오디오 동의 파일을 포함하여 성우 프로필을 지정해야 합니다. 사용자 지정 신경망은 제한된 액세스로 사용할 수 있습니다. [책임 있는 AI 요구 사항](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)을 이해하고 [여기에서 액세스 권한을 적용](https://aka.ms/customneural)합니다. 
    
    이 페이지에서는 테스트를 위해 스크립트를 업로드하도록 선택할 수도 있습니다. 테스트 스크립트는 1Mb보다 작은 txt 파일이여야 합니다. 지원되는 인코딩 형식으로는 ANSI/ASCII, UTF-8, UTF-8-BOM, UTF-16-LE 또는 UTF-16-BE가 있습니다. 발화의 각 단락마다 별도의 오디오가 생성됩니다. 모든 문장을 하나의 오디오로 결합하려면 이를 한 단락으로 만듭니다. 

6. **학습** 을 클릭하여 음성 모델 만들기를 시작합니다.

학습 테이블은 새로 만든 이 모델에 해당하는 새 항목을 표시합니다. 또한 테이블에는 처리 중, 성공, 실패 등의 상태가 표시됩니다.

테이블에 표시되는 상태는 다음과 같이 데이터 세트를 음성 모델로 변환하는 프로세스를 반영합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델을 만들고 있습니다. |
| 성공 | 음성 모델을 만들었으며 배포할 수 있습니다. |
| 실패 | 보이지 않는 데이터 문제 또는 네트워크 문제 등 여러 가지 이유로 인해 음성 모델이 학습에 실패했습니다. |

학습 시간은 처리된 오디오 데이터의 양과 선택한 학습 방법에 따라 다릅니다. 범위는 30분에서 40시간까지 입니다. 모델 학습이 성공하면 테스트를 시작할 수 있습니다. 

> [!NOTE]
> 무료 구독(F0) 사용자는 한 음성 글꼴을 동시에 학습시킬 수 있습니다. 표준 구독(S0) 사용자는 세 개의 음성을 동시에 학습시킬 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 사용자 지정 신경망 학습은 무료가 아닙니다. 여기에서 [가격 책정](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)을 확인하세요. 

> [!NOTE]
> 구독당 학습시킬 수 있는 최대 음성 모델 수는 무료 구독(F0) 사용자의 경우 10개 모델이고 표준 구독(S0) 사용자의 경우 100개입니다.

신경망 음성 학습 기능을 사용하는 경우 실시간 스트리밍 시나리오에 최적화된 모델 또는 비동기 [긴 오디오 합성](long-audio-api.md)에 최적화된 HD 신경 모델을 학습하도록 선택할 수 있습니다.  

## <a name="test-your-voice-model"></a>음성 모델 테스트

각 학습에서는 모델을 테스트하는 데 도움이 되는 샘플 오디오 파일 100개를 자동으로 생성합니다. 음성 모델을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

1.  **텍스트 음성 변환 > Custom Voice> [프로젝트 이름]> 모델** 로 이동합니다.

2.  테스트하려는 모델의 이름을 클릭합니다.

3.  모델 세부 정보 페이지의 **테스트** 탭에서 샘플 오디오 파일을 찾을 수 있습니다. 

음성의 품질은 학습 데이터의 크기, 녹음 음질, 음성 텍스트 파일의 정확도, 학습 데이터의 녹음 음성이 원하는 사용 사례에 맞게 디자인된 음색과 일치하는 정도 등 다양한 요인에 따라 달라집니다. [여기에서 당사 기술의 기능 및 한계 그리고 모델 품질 향상을 위한 모범 사례에 대해 자세히 알아보세요](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext). 

## <a name="create-and-use-a-custom-voice-endpoint"></a>사용자 지정 음성 엔드포인트 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 엔드포인트는 글꼴을 배포하는 데 사용한 구독으로만 호출할 수 있습니다.

새 사용자 지정 음성 엔드포인트를 만들려면 **텍스트 음성 변환 > Custom Voice > 엔드포인트** 로 이동합니다. **엔드포인트 추가** 를 선택하고 사용자 지정 엔드포인트에 대한 **이름** 및 **설명** 을 입력합니다. 그런 다음, 이 엔드포인트와 연결할 사용자 지정 음성 모델을 선택합니다.

**추가** 단추를 클릭하면 엔드포인트 테이블에 새 엔드포인트에 대한 항목이 표시됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공** 이면 엔드포인트를 사용할 준비가 완료된 것입니다.

엔드포인트를 항상 사용하지 않는 경우 **일시 중단** 및 **계속** 할 수 있습니다. 일시 중단 후 엔드포인트가 다시 활성화되면 엔드포인트 URL은 동일하게 유지되므로 앱에서 코드를 변경할 필요가 없습니다. 

엔드포인트를 새 모델로 업데이트할 수도 있습니다. 모델을 변경하려면 새 모델의 이름을 업데이트하려는 것과 동일하게 지정해야 합니다. 

> [!NOTE]
> 무료 구독(F0) 사용자는 하나의 모델만 배포할 수 있습니다. 표준 구독(S0) 사용자는 각각 자체 사용자 지정 음성이 있는 최대 50개의 엔드포인트를 만들 수 있습니다.

> [!NOTE]
> 사용자 지정 음성을 사용하려면 음성 모델 이름을 지정하고, HTTP 요청에서 직접 사용자 지정 URI를 사용하고, 동일한 구독을 사용하여 TTS 서비스의 인증을 통과해야 합니다.

엔드포인트가 배포된 후에는 엔드포인트 이름이 링크로 표시됩니다. 엔드포인트 키, 엔드포인트 URL 및 샘플 코드와 같이 엔드포인트 관련 정보를 표시하려면 링크를 클릭합니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 엔드포인트를 테스트하려면 **엔드포인트 세부 정보** 페이지에서 **엔드포인트 확인** 을 선택합니다. 엔드포인트 테스트 페이지가 나타납니다. 텍스트 상자에 말할 텍스트(일반 텍스트 또는 [SSML 형식](speech-synthesis-markup.md))를 입력합니다. **재생** 을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 이 테스트 기능은 사용자 지정 음성 합성 사용에 대해 요금이 부과됩니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [가이드: 음성 샘플 기록](record-custom-voice-samples.md)
* [텍스트 음성 변환 API 참조](rest-text-to-speech.md)
* [긴 오디오 API](long-audio-api.md)