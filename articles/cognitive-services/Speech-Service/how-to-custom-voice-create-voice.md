---
title: Custom Voice 만들기 - Speech Service
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되면 Custom Voice 포털로 이동합니다. Custom Voice 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘 및 성별 속성을 공유해야 합니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 449975a6f0b5799ce93dcb31f42e1a43a1d183f3
ms.sourcegitcommit: c385af80989f6555ef3dadc17117a78764f83963
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 06/04/2021
ms.locfileid: "111412136"
---
# <a name="create-and-use-your-voice-model"></a>음성 모델 만들기 및 사용

[학습 데이터 준비](how-to-custom-voice-prepare-data.md)에서 사용자 지정 신경망 음성 및 다양한 형식 요구 사항을 학습하는 데 사용할 수 있는 다양한 데이터 형식에 대해 배웠습니다. 데이터와 성우의 성우 구술문을 준비한 후에는 [Speech Studio](https://aka.ms/custom-voice-portal)로 업로드를 시작할 수 있습니다. 이 문서에서는 Speech Studio 포털을 통해 사용자 지정 신경망 음성 학습하는 방법을 알아봅니다. 사용자 지정 신경망 음성에 대해 [지원되는 언어](language-support.md#customization)를 참조하세요.

## <a name="prerequisites"></a>사전 요구 사항

* [사용자 지정 신경망 음성 시작](how-to-custom-voice.md) 완료
* [학습 데이터 준비](how-to-custom-voice-prepare-data.md)

## <a name="set-up-voice-talent"></a>성우 설정

성우란 신경망 음성 모델을 만들기 위해 음성을 녹음하는 개인 또는 대상 화자입니다. 음성을 만들기 전에 음성 가상 사용자를 정의하고 적절한 성우를 선정합니다. 음성 샘플 녹음에 대한 자세한 내용은 [자습서](record-custom-voice-samples.md)를 참조하세요.

신경망 음성을 학습하려면 자신의 음성 데이터를 사용하여 사용자 지정 음성 모델을 학습시키는 데 동의한 성우가 녹음한 오디오 파일이 있는 성우 프로필을 만들어야 합니다. 녹음 스크립트를 준비할 때 다음과 같은 문장을 포함해야 합니다.

**"나[성 및 이름]는 내 음성의 합성 버전을 만들고 사용하기 위해 [회사 이름]에서 내 음성 녹음이 사용된다는 것을 알고 있습니다."**
이 문장은 학습 데이터가 동의문의 오디오와 일치하는지 확인하는 데 사용됩니다. > 여기에서 [성우 확인](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)에 대해 자세히 알아보세요.

> [!NOTE]
> 사용자 지정 신경망은 제한된 액세스로 사용할 수 있습니다. [책임 있는 AI 요구 사항](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)을 이해한 다음, [액세스 권한을 적용](https://aka.ms/customneural)해야 합니다. 

다음 단계에서는 성우의 성우 언어 동의 파일을 준비했다고 가정합니다.  [Speech Studio](https://aka.ms/custom-voice-portal)로 이동하여 사용자 지정 신경망 음성 프로젝트를 선택한 다음, 다음 단계에 따라 성우 프로필을 만듭니다.

1. **텍스트 음성 변환** > **사용자 지정 음성** > **프로젝트 선택** > **성우 설정** 을 진행합니다.

2. **성우 추가** 를 클릭합니다.

3. 다음으로, 음성 특성을 정의하려면 사용할 **대상 시나리오** 를 클릭합니다. 그런 다음, **음성 특성** 을 설명합니다.

> [!NOTE]
> 제공하는 시나리오는 애플리케이션 양식에 신청한 내용과 일관되어야 합니다.

4. 그런 다음, **성우 문 업로드** 로 이동하여 지침에 따라 미리 준비한 성우 문을 업로드합니다.

> [!NOTE]
> 녹음 환경 및 말하기 스타일을 비롯하여 구술문이 학습 데이터와 동일한 설정으로 녹음되도록 해야 합니다.

5. 마지막으로 **검토 및 제출** 로 이동하여 설정을 검토하고 **제출** 을 클릭합니다.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가 되면 **학습 데이터 준비** 탭으로 이동하여 첫 번째 학습 세트를 추가하고 데이터를 업로드합니다.  학습 세트는 음성 모델 학습에 사용되는 오디오 발화 및 해당 매핑 스크립트의 세트입니다. 학습 세트를 사용하여 학습 데이터를 구성할 수 있습니다. 데이터 준비 상태 검사는 각 학습 세트별로 수행됩니다. 여러 데이터 세트를 학습 세트로 가져올 수 있습니다.

다음을 수행하여 학습 데이터를 만들고 검토할 수 있습니다.

1. **학습 데이터 준비** 탭에서 **학습 세트 추가** 를 클릭하여 **이름** 및 **설명** > **만들기** 를 입력하여 새 학습 세트를 추가합니다.

   학습 세트가 성공적으로 만들어지면 데이터 업로드를 시작할 수 있습니다. 

2. 데이터를 업로드하려면 **데이터 업로드** > **데이터 형식 선택** > **데이터 업로드** 를 클릭하고 **대상 학습 세트를 지정하고** > 데이터 세트에 대한 **이름** 및 **설명** 을 입력한 다음 > 설정을 검토하고 **업로드** 를 클릭합니다.

> [!NOTE]
>- 중복된 오디오 이름은 학습에서 제거됩니다. 선택한 데이터 세트에 한 개 또는 여러 .zip 파일에 동일한 오디오 이름이 포함되지 않도록 해야 합니다. 발화 ID(오디오 또는 스크립트 파일)가 중복되는 경우 거부됩니다.
>- 이전 버전의 Speech Studio에서 데이터 세트를 만든 경우 데이터 세트에 대한 학습 세트를 미리 지정해야 사용할 수 있습니다. 그렇지 않으면 느낌표가 데이터 세트 이름에 추가되고 데이터 세트를 사용할 수 없게 됩니다.

업로드하는 각 데이터 세트는 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 사용자 지정 신경망 음성 서비스에서 데이터를 정확하게 처리하도록 업로드하기 전에 데이터의 형식을 올바르게 지정하는 것이 중요합니다. [학습 데이터 준비](how-to-custom-voice-prepare-data.md)로 이동하여 데이터 형식이 올바른지 확인합니다.

> [!NOTE]
> - 표준 구독(S0) 사용자는 다섯 개의 데이터 세트를 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.
> - 구독당 가져올 수 있는 최대 데이터 세트 수는 무료 구독(F0) 사용자의 경우 10개의 .zip 파일이고 표준 구독(S0) 사용자의 경우 500개입니다.

**업로드** 단추를 누르면 데이터 세트의 유효성이 자동으로 검사됩니다. 데이터 유효성 검사에는 오디오 파일의 파일 형식, 크기 및 샘플링 레이트를 확인하는 일련의 검사가 포함됩니다. 오류가 있으면 이를 수정하고 다시 제출합니다. 

데이터가 업로드되면 학습 세트 세부 정보 보기에서 세부 정보를 확인할 수 있습니다. **개요** 탭에서 각 데이터 세트의 발음 점수와 잡음 수준을 추가로 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

**데이터 세부 정보** 에서 학습 세트의 데이터 세부 정보를 확인할 수 있습니다. 데이터에 대한 몇 가지 일반적인 문제가 있는 경우 표시된 메시지의 지침에 따라 학습 전에 수정합니다.

문제는 세 가지 유형으로 나뉩니다. 다음 세 개의 표를 참조하여 각 오류 유형을 확인합니다.

아래 표에 나열된 첫 번째 유형의 오류는 수동으로 수정해야 합니다. 그렇지 않으면 이러한 오류가 있는 데이터는 학습 중에 제외됩니다. 

| 범주 | 이름 | Description | 제안 해결 방법 |
| --------- | ----------- | ----------- | --------------------------- |
| 스크립트 | 잘못된 구분 기호| 이러한 스크립트 줄에는 유효한 구분 기호 TAB:{}이 없습니다.| TAB을 사용하여 ID와 콘텐츠를 구분합니다.|
| 스크립트 | 잘못된 스크립트 ID| 스크립트 ID 형식이 잘못되었습니다.| 스크립트 줄 ID는 숫자여야 합니다.|
| 스크립트 | 스크립트 콘텐츠가 중복됨| 줄 {} 스크립트 콘텐츠가 줄 {}와 중복됩니다.| 스크립트 줄 콘텐츠는 고유해야 합니다.|
| 스크립트 | 스크립트 콘텐츠가 너무 김| 스크립트 줄 콘텐츠가 최대 1000보다 깁니다.| 스크립트 줄 콘텐츠 길이는 1000자 미만이어야 합니다.|
| 스크립트 | 스크립트에 일치하는 오디오가 없음| 스크립트 줄 ID에 일치하는 오디오가 없습니다.| 스크립트 줄 ID는 오디오 ID와 일치해야 합니다.|
| 스크립트 | 유효한 스크립트 없음| 이 데이터 세트에서 유효한 스크립트를 찾을 수 없습니다.| 자세한 문제 목록에 따라 문제가 있는 스크립트 줄을 수정합니다.|
| 오디오 | 오디오에 일치하는 스크립트가 없음| 오디오 파일이 스크립트 ID와 일치하지 않습니다.| wav 파일 이름은 스크립트 파일의 ID와 일치해야 합니다.|
| 오디오 | 잘못된 오디오 형식| wav 파일의 형식이 잘못되었으며 읽을 수 없습니다.| sox와 같은 오디오 도구로 wav 파일 형식을 확인합니다.|
| 오디오 | 낮은 샘플링 레이트| 오디오 샘플링 레이트가 16KHz보다 낮습니다. | wav 파일 샘플링 레이트는 16KHz 이상이어야 합니다. |
| 오디오 | 오디오 시간이 너무 김| 오디오 시간이 30초보다 깁니다.| 시간이 긴 오디오를 여러 파일로 분할하여 각각 15초 미만인지 확인합니다.|
| 오디오 | 유효한 오디오 없음| 이 데이터 세트에서 유효한 오디오를 찾을 수 없습니다.| 자세한 문제 목록에 따라 문제가 있는 오디오를 수정합니다.|

아래 표에 나열된 두 번째 유형의 오류는 자동으로 수정되지만 고정된 데이터를 다시 확인하는 것이 좋습니다. 

| 범주 | 이름 | Description | 제안 해결 방법 |
| --------- | ----------- | ----------- | --------------------------- |
| 오디오 | 스테레오 오디오 | 스테레오 오디오의 채널 하나만 TTS 모델 학습에 사용됩니다.|     TTS 레코딩 또는 데이터 준비 시 모노를 사용합니다. 이 오디오는 모노로 변환됩니다. 정규화된 데이터 세트를 다운로드하고 검토합니다.|
| 볼륨 | 볼륨이 최고 범위를 벗어남 |볼륨 최댓값이 -3dB(최대 볼륨의 70%)에서 -6dB(50%) 범위 내에 있지 않습니다. -4dB(65%)로 자동 조정됩니다.|  레코딩 또는 데이터 준비 중에 볼륨 최댓값을 적절한 범위로 제어합니다. 이 오디오는 최대 범위에 맞게 선형으로 확장됩니다. 정규화된 데이터 세트를 다운로드하고 검토합니다.|
|불일치 | 첫 번째 단어 전에 긴 무음이 감지됨 | 첫 번째 단어 전에 긴 무음이 감지되었습니다.| 시작 무음은 200ms로 잘립니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 | 마지막 단어 후에 긴 무음이 감지됨 | 마지막 단어 후에 긴 무음이 감지되었습니다. | 종료 무음은 200ms로 잘립니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 |시작 무음이 너무 짧음 | 시작 무음이 100ms보다 짧습니다. | 시작 무음이 100ms로 확장됩니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 | 종료 무음이 너무 짧음 | 종료 무음이 100ms보다 짧습니다. | 종료 무음이 100ms로 확장됩니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |

아래 표에 나열된 세 번째 오류 유형이 수정되지 않은 경우 이러한 오류가 있는 데이터는 학습 중에 제외되지는 않지만 학습 품질에 영향을 미칩니다. 고품질 학습의 경우 이러한 오류를 수동으로 수정하는 것이 좋습니다. 

| 범주 | 이름 | Description | 제안 해결 방법 |
| --------- | ----------- | ----------- | --------------------------- |
| 스크립트 | 숫자 0-9 포함| 이러한 스크립트 줄에 숫자 0-9가 포함됩니다.| 이러한 스크립트 줄에 숫자 0-9가 포함됩니다. 정규화된 단어로 확장하고 오디오와 일치시킵니다. 예를 들어 ‘123’을 ‘백이십삼’으로 바꿉니다.|
| 스크립트 | 발음이 혼동된 단어 ‘{}’ | 스크립트에 발음 혼동 단어 ‘{}’가 포함되어 있습니다.| 단어를 실제 발음으로 확장합니다. 예들 들어 {}입니다.|
| 스크립트 | 질문 발화가 너무 적음| 질문 스크립트 줄이 총 스크립트 줄의 1/6 미만입니다.| 질문 스크립트 줄은 질문 어조를 올바르게 표현하는 음성 글꼴의 총 줄 수 중 1/6 이상이어야 합니다.|
| 스크립트 | 느낌표 발화가 너무 적음| 느낌표 스크립트 줄이 총 스크립트 줄의 1/6 미만입니다.| 느낌표 스크립트 줄은 느낌표 어조를 올바르게 표현하는 음성 글꼴에 대해 총 줄의 1/6 이상이어야 합니다.|
| 오디오| 신경망 음성에 대해 샘플링 레이트가 낮음 | 오디오 샘플링 레이트가 24KHz보다 낮습니다.|    wav 파일 샘플링 레이트는 고품질 신경망 음성의 경우 24KHz보다 높거나 같아야 합니다.|
| 볼륨 | 전체 볼륨이 너무 낮음 | {} 샘플의 볼륨이 -18dB(최대 볼륨의 10%)보다 낮습니다.|     레코딩 또는 데이터 준비 중에 볼륨 평균 수준을 적절한 범위로 제어합니다.|
| 볼륨 | 볼륨 잘림| 볼륨 잘림이 {}에서 감지됩니다.| 최댓값에서 볼륨 잘림을 방지하도록 레코딩 장비를 조정합니다.|
| 볼륨 | 시작 무음이 깨끗하지 않음 | 처음 100ms 무음이 깨끗하지 않습니다. -40dB(최대 볼륨의 1%)보다 큰 볼륨이 감지됩니다.|    레코딩 잡음층 수준을 낮추고 처음 100ms를 무음으로 둡니다.|
| 볼륨| 종료 무음이 깨끗하지 않음| 마지막 100ms 무음이 깨끗하지 않습니다. -40dB(최대 볼륨의 1%)보다 큰 볼륨이 감지됩니다.|     레코딩 잡음층 수준을 낮추고 마지막 100ms를 무음으로 둡니다.|
| 불일치 | 스크립트 오디오 불일치가 감지됨| 스크립트와 오디오 콘텐츠가 일치하지 않습니다. |     스크립트와 오디오 콘텐츠를 검토하여 이러한 항목이 일치하는지 확인하고 잡음층 수준을 제어합니다. 긴 무음 시간을 줄이거나 여러 발언으로 분할합니다.|
| 불일치 | 첫 단어 전에 추가 오디오 에너지가 검색됨 |    첫 단어 전에 추가 오디오 에너지가 검색됩니다. 또한 첫 번째 단어 전에 시작 무음이 너무 짧기 때문일 수도 있습니다.|    스크립트와 오디오 콘텐츠를 검토하여 이러한 항목이 일치하는지 확인하고 잡음층 수준을 제어합니다. 또한 첫 번째 단어 전에 100ms를 무음으로 둡니다.|
| 불일치 | 마지막 단어 후에 추가 오디오 에너지가 감지됨| 마지막 단어 후에 추가 오디오 에너지가 감지됩니다. 또한 마지막 단어 후에 무음이 너무 짧기 때문일 수도 있습니다.|    스크립트와 오디오 콘텐츠를 검토하여 이러한 항목이 일치하는지 확인하고 잡음층 수준을 제어합니다. 또한 마지막 단어 후에 100ms를 무음으로 둡니다.|
| 불일치 | 낮은 신호 대 잡음 비율 | 오디오 SNR 수준이 {}dB보다 낮습니다.| 레코딩 또는 데이터 준비 중에 오디오 잡음 수준을 낮춥니다.|
| 불일치 | 음성 콘텐츠 인식 실패 | 이 오디오에서 음성 인식을 수행하지 못했습니다.|  오디오 및 스크립트 콘텐츠를 확인하여 오디오가 유효한 음성이며 스크립트와 일치하는지 확인합니다.|

## <a name="train-your-custom-neural-voice-model"></a>사용자 지정 신경망 음성 모델 학습

유효성이 검사된 데이터 세트는 사용자 지정 신경망 음성 모델을 빌드하는 데 사용할 수 있습니다.

1. **모델 학습** 탭에서 **모델 학습** 을 클릭하여 업로드한 데이터로 음성 모델을 만듭니다.

2. 모델 및 대상 언어에 사용할 신경망 학습 방법을 선택합니다.

기본적으로 음성 모델은 학습 데이터와 동일한 언어로 학습됩니다. 음성 모델에 대한 보조 언어(미리 보기)를 만들도록 선택할 수도 있습니다.  사용자 지정 신경망 음성 및 교차 다국어 기능에 대해 지원되는 언어를 확인하세요([사용자 지정을 위한 언어](language-support.md#customization)).

3. 다음으로, 학습에 사용할 데이터 세트를 선택하고 화자 파일을 지정합니다.

>[!NOTE]
>- 사용자 지정 신경망 음성을 만들려면 최소 300개의 발화를 선택해야 합니다.
>- 신경망 음성을 학습하려면 자신의 음성 데이터를 사용자 지정 음성 모델을 학습시키는 데 사용할 것을 승인한 성우가 제공한 오디오 동의 파일을 포함한 성우 프로필을 지정해야 합니다. 사용자 지정 신경망은 제한된 액세스로 사용할 수 있습니다. [책임 있는 AI 요구 사항](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)을 이해하고 [여기에서 액세스 권한을 적용](https://aka.ms/customneural)합니다.
>- 이 페이지에서는 테스트를 위해 스크립트를 업로드하도록 선택할 수도 있습니다. 테스트 스크립트는 1Mb보다 작은 txt 파일이여야 합니다. 지원되는 인코딩 형식으로는 ANSI/ASCII, UTF-8, UTF-8-BOM, UTF-16-LE 또는 UTF-16-BE가 있습니다. 발화의 각 단락마다 별도의 오디오가 생성됩니다. 모든 문장을 하나의 오디오로 결합하려면 이를 한 단락으로 만듭니다.

4. 그런 다음, 이 모델을 식별하는 데 도움이 되는 **이름** 및 **설명** 을 입력합니다.

신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 몇 가지 문장 부호 문자(예: -, \_ 및 (', '))만 허용됩니다. 신경망 음성 모델마다 다른 이름을 사용합니다.

**설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 세트의 이름을 기록하는 것입니다.

5. 설정을 검토한 다음, **제출** 을 클릭하여 모델 학습을 시작합니다.

> [!NOTE]
> 중복된 오디오 이름은 학습에서 제거됩니다. 선택한 데이터 세트에 여러 .zip 파일에 동일한 오디오 이름이 포함되지 않도록 합니다.

**모델 학습** 테이블은 새로 만든 이 모델에 해당하는 새 항목을 표시합니다. 또한 테이블에는 처리 중, 성공, 실패 등의 상태가 표시됩니다.

테이블에 표시되는 상태는 다음과 같이 데이터 세트를 음성 모델로 변환하는 프로세스를 반영합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델을 만들고 있습니다. |
| 성공 | 음성 모델을 만들었으며 배포할 수 있습니다. |
| 실패 | 보이지 않는 데이터 문제 또는 네트워크 문제 등 여러 가지 이유로 인해 음성 모델이 학습에 실패했습니다. |

학습 기간은 학습하는 데이터 양에 따라 달라집니다. 사용자 지정 신경망 음성을 학습하는 데 평균 40 컴퓨팅 시간이 소요됩니다. 

> [!NOTE]
> 사용자 지정 신경망 음성의 학습은 무료가 아닙니다. 여기에서 [가격 책정](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)을 확인하세요. 표준 구독(S0) 사용자는 세 개의 음성을 동시에 학습시킬 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요. 

6. 모델 학습을 성공적으로 완료한 후에는 모델 세부 정보를 검토할 수 있습니다.

각 학습에서는 모델을 테스트하는 데 도움이 되는 샘플 오디오 파일 100개를 자동으로 생성합니다. 음성 모델을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

음성의 품질은 학습 데이터의 크기, 레코딩 품질, 대본 파일의 정확도, 학습 데이터의 녹음된 음성이 원하는 사용 사례에 맞게 디자인된 음색과 일치하는 정도 등 다양한 요인에 따라 달라집니다. [여기에서 당사 기술의 기능 및 한계 그리고 모델 품질 향상을 위한 모범 사례에 대해 자세히 알아보세요](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext). 

## <a name="create-and-use-a-custom-neural-voice-endpoint"></a>사용자 지정 신경망 음성 엔드포인트 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 엔드포인트는 글꼴을 배포하는 데 사용한 구독으로만 호출할 수 있습니다.

다음 작업을 수행하여 사용자 지정 신경망 음성 엔드포인트를 만들 수 있습니다.

1. **모델 배포** 탭에서 **모델 배포** 를 클릭합니다. 
2. 다음으로, 사용자 지정 엔드포인트에 대한 **이름** 및 **설명** 을 입력합니다.
3. 그런 다음, 이 엔드포인트와 연결할 음성 모델을 선택합니다. 
4. 마지막으로 **배포** 를 클릭하여 엔드포인트를 만듭니다.

**배포** 단추를 클릭하면 엔드포인트 테이블에 새 엔드포인트에 대한 항목이 표시됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공** 이면 엔드포인트를 사용할 준비가 완료된 것입니다.

엔드포인트를 항상 사용하지 않는 경우 **일시 중단** 및 **계속** 할 수 있습니다. 일시 중단 후 엔드포인트가 다시 활성화되면 엔드포인트 URL은 동일하게 유지되므로 앱에서 코드를 변경할 필요가 없습니다. 

엔드포인트를 새 모델로 업데이트할 수도 있습니다. 모델을 변경하려면 새 모델의 이름을 업데이트하려는 것과 동일하게 지정해야 합니다. 

> [!NOTE]
>- 표준 구독(S0) 사용자는 각각 자체 사용자 지정 신경망 음성이 포함된 엔드포인트를 50개까지 만들 수 있습니다.
>- 사용자 지정 신경망 음성을 사용하려면 음성 모델 이름을 지정하고, HTTP 요청에서 직접 사용자 지정 URI를 사용하고, 동일한 구독을 사용하여 TTS 서비스의 인증을 통과해야 합니다.

엔드포인트가 배포된 후에는 엔드포인트 이름이 링크로 표시됩니다. 엔드포인트 키, 엔드포인트 URL 및 샘플 코드와 같이 엔드포인트 관련 정보를 표시하려면 링크를 클릭합니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다.  자세한 내용은 [Speech SDK](./get-started-text-to-speech.md) 또는 [REST API](rest-text-to-speech.md)를 참조하세요.

또한 친숙한 UI를 사용하여 오디오 출력을 세밀하게 조정할 수 있도록 하는 온라인 도구인 [오디오 콘텐츠 만들기](https://speech.microsoft.com/audiocontentcreation)도 사용할 수 있습니다.

## <a name="next-steps"></a>다음 단계

- [음성 샘플 녹음 방법](record-custom-voice-samples.md)
- [텍스트 음성 변환 API 참조](rest-text-to-speech.md)
- [긴 오디오 API](long-audio-api.md)