---
title: 사용자 지정 음성-음성 서비스 만들기
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되 면 사용자 지정 음성 포털로 이동 합니다. 사용자 지정 음성 프로젝트를 만들거나 선택 합니다. 프로젝트는 음성 학습에 사용할 데이터와 올바른 언어/로캘 및 성별 속성을 공유 해야 합니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: bbe1d651a7d2d2cac1b1aa78b815b2797ad185c5
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/24/2020
ms.locfileid: "76717320"
---
# <a name="create-a-custom-voice"></a>사용자 지정 음성 만들기

[사용자 지정 음성에 대 한 데이터 준비](how-to-custom-voice-prepare-data.md)에서는 사용자 지정 음성 및 다양 한 형식 요구 사항을 학습 하는 데 사용할 수 있는 다양 한 데이터 형식에 대해 설명 했습니다. 데이터를 준비한 후 [사용자 지정 음성 포털](https://aka.ms/custom-voice-portal)또는 사용자 지정 음성 학습 API를 통해 업로드를 시작할 수 있습니다. 여기서는 포털을 통해 사용자 지정 음성을 학습 하는 단계를 설명 합니다.

> [!NOTE]
> 이 페이지에서는 사용자 지정 음성 [시작](how-to-custom-voice.md) 및 사용자 지정 음성 [에 대 한 데이터 준비](how-to-custom-voice-prepare-data.md)를 읽고 사용자 지정 음성 프로젝트를 만들었다고 가정 합니다.

사용자 지정 음성: [언어](language-support.md#customization)에 대해 지원 되는 언어를 확인 합니다.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가 되 면 [사용자 지정 음성 포털로](https://aka.ms/custom-voice-portal)이동 합니다. 사용자 지정 음성 프로젝트를 만들거나 선택 합니다. 프로젝트는 음성 학습에 사용할 데이터와 올바른 언어/로캘 및 성별 속성을 공유 해야 합니다. 예를 들어, 영어 (영국)를 영국 강조 표시 하 여 오디오 녹음을 사용 하는 경우 `en-GB`를 선택 합니다.

**데이터** 탭으로 이동 하 고 **데이터 업로드**를 클릭 합니다. 마법사에서 준비한 항목과 일치 하는 올바른 데이터 형식을 선택 합니다.

업로드하는 각 데이터 집합은 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 업로드되기 전에 데이터의 형식을 올바르게 지정하는 것이 중요합니다. 이렇게 하면 사용자 지정 음성 서비스에서 데이터를 정확 하 게 처리할 수 있습니다. [사용자 지정 음성의 데이터 준비](how-to-custom-voice-prepare-data.md) 로 이동 하 여 데이터의 형식이 최적의 확인 합니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 두 데이터 집합을 동시에 업로드할 수 있습니다. 표준 구독 (S0) 사용자는 5 개의 데이터 집합을 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 구독 당 가져올 수 있는 최대 데이터 집합 수는 무료 구독 (F0) 사용자의 경우 10 개의 .zip 파일이 고, 표준 구독 (S0) 사용자의 경우 500입니다.

업로드 단추를 누르면 데이터 집합의 유효성이 자동으로 검사 됩니다. 데이터 유효성 검사에는 파일 형식, 크기 및 샘플링 주기를 확인할 수 있는 오디오 파일의 일련의 검사가 포함 되어 있습니다. 오류를 수정 하 고 다시 제출 합니다. 데이터 가져오기 요청이 성공적으로 시작 되 면 방금 업로드 한 데이터 집합에 해당 하는 데이터 테이블의 항목이 표시 됩니다.

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다.

| 상태 | 의미 |
| ----- | ------- |
| 처리 | 데이터 집합을 수신 하 여 처리 하 고 있습니다. |
| 성공 | 데이터 집합의 유효성을 검사 하 고 이제 음성 모델을 빌드하는 데 사용할 수 있습니다. |
| 실패 | 여러 가지 원인 (예: 파일 오류, 데이터 문제 또는 네트워크 문제)으로 인해 처리 하는 동안 데이터 집합에 오류가 발생 했습니다. |

유효성 검사가 완료 된 후 **길이 발언** 열에서 각 데이터 집합에 대해 일치 하는 길이 발언의 총 수를 볼 수 있습니다. 선택한 데이터 형식에 긴 오디오 조각화가 필요한 경우이 열에는 기록에 따라 또는 음성 기록 서비스를 통해 사용자가 분할 한 길이 발언 반영 됩니다. 유효성을 검사 한 데이터 집합을 추가로 다운로드 하 여 성공적으로 가져온 길이 발언의 세부 결과와 해당 매핑 기록을 볼 수 있습니다. 힌트: 긴 오디오 조각화는 데이터 처리를 완료 하는 데 1 시간 이상 걸릴 수 있습니다.

En-us 및 zh-cn 데이터 집합의 경우 보고서를 추가로 다운로드 하 여 각 기록의 발음 점수와 노이즈 수준을 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

## <a name="build-your-custom-voice-model"></a>사용자 지정 음성 모델 빌드

데이터 집합의 유효성을 검사 한 후에는이를 사용 하 여 사용자 지정 음성 모델을 빌드할 수 있습니다.

1.  **텍스트 음성 변환 > 사용자 지정 음성 > 학습**으로 이동 합니다.

2.  **모델 학습**을 클릭 합니다.

3.  그런 다음이 모델을 식별 하는 데 도움이 되는 **이름** 및 **설명을** 입력 합니다.

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및-, \_, (', ')와 같은 몇 가지 문장 부호 문자만 사용할 수 있습니다. 음성 모델 마다 다른 이름을 사용 합니다.

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 세트의 이름을 기록하는 것입니다.

4.  **학습 데이터 선택** 페이지에서 학습에 사용할 데이터 집합을 하나 또는 여러 개 선택 합니다. 제출 하기 전에 길이 발언 수를 확인 합니다. En-us 및 zh-cn 음성 모델에 대해 원하는 수의 길이 발언를 시작할 수 있습니다. 다른 로캘의 경우 음성을 학습 하려면 2000 길이 발언 이상을 선택 해야 합니다.

    > [!NOTE]
    > 중복 된 오디오 이름은 학습에서 제거 됩니다. 선택한 데이터 집합에 여러 개의 .zip 파일 간에 동일한 오디오 이름이 포함 되지 않도록 합니다.

    > [!TIP]
    > 품질 결과에는 동일한 스피커의 데이터 집합을 사용 해야 합니다. 학습을 위해 제출한 데이터 집합의 총 수가 6000 길이 발언 미만인 경우 통계 패라메트릭 합성 기술을 통해 음성 모델을 학습 합니다. 학습 데이터가 총 6000 개의 고유 길이 발언을 초과 하는 경우 연결 합성 기법을 사용 하 여 학습 프로세스를 시작 합니다. 일반적으로 연결 기술은 보다 자연스럽 게 향상 된 음성 결과를 발생 시킬 수 있습니다. 공개적으로 사용 가능한 [신경망](language-support.md#neural-voices)에 해당 하는 디지털 음성을 생성할 수 있는 최신 신경망 기술을 사용 하 여 모델을 학습 하려면 [사용자 지정 음성 팀에 문의 하세요](https://go.microsoft.com/fwlink/?linkid=2108737) .

5.  **학습** 을 클릭 하 여 음성 모델 만들기를 시작 합니다.

학습 표는 새롭게 생성된 모델에 해당하는 새 항목을 표시합니다. 또한 테이블에는 처리 중, 성공, 실패 됨 상태가 표시 됩니다.

표시 된 상태는 여기에 표시 된 것 처럼 데이터 집합을 음성 모델로 변환 하는 프로세스를 반영 합니다.

| 상태 | 의미 |
| ----- | ------- |
| 처리 | 음성 모델을 만들고 있습니다. |
| 성공 | 음성 모델을 만들고 배포할 수 있습니다. |
| 실패 | 다양 한 원인 (예: 보이지 않는 데이터 문제 또는 네트워크 문제)으로 인해 학습에서 음성 모델이 실패 했습니다. |

학습 시간은 처리되는 오디오 데이터의 양에 따라 달라집니다. 일반적인 시간 범위는 수백 개 발화에 해당하는 약 30분에서 20,000개 발화에 해당하는 40시간 정도입니다. 모델 교육이 성공적으로 완료 되 면 테스트를 시작할 수 있습니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 한 음성 글꼴을 동시에 학습 시킬 수 있습니다. 표준 구독 (S0) 사용자는 세 개의 음성을 동시에 학습할 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 구독 당 교육을 받을 수 있는 최대 음성 모델 수는 10 개의 무료 구독 (F0) 사용자와 S0 (standard subscription) 사용자를 위한 100 모델입니다.

신경망 학습 기능을 사용 하는 경우 실시간 스트리밍 시나리오에 최적화 된 모델 또는 비동기 [긴 오디오 합성](long-audio-api.md)에 최적화 된 HD 신경망 모델을 학습 하도록 선택할 수 있습니다.  

## <a name="test-your-voice-model"></a>음성 모델 테스트

음성 글꼴을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

1.  **텍스트 음성 변환 > 사용자 지정 음성 > 테스트**로 이동 합니다.

2.  **테스트 추가**를 클릭 합니다.

3.  테스트할 모델을 하나 이상 선택 하십시오.

4.  음성으로 사용할 텍스트를 입력 합니다. 한 번에 여러 모델을 테스트 하도록 선택한 경우 다른 모델에 대 한 테스트에 동일한 텍스트가 사용 됩니다.

    > [!NOTE]
    > 텍스트의 언어는 음성 글꼴의 언어와 같아야 합니다. 성공적으로 학습 된 모델만 테스트할 수 있습니다. 이 단계에서는 일반 텍스트만 지원 됩니다.

5.  **만들기**를 클릭합니다.

테스트 요청을 제출한 후에는 테스트 페이지로 돌아갑니다. 이제 테이블에는 새 요청에 해당하는 항목과 익숙한 상태 열이 포함됩니다. 음성을 합성하는 데 몇 분 정도 걸릴 수 있습니다. 상태 열에 **Succeeded**가 표시 되 면 오디오를 재생 하거나 텍스트 입력 (.txt 파일) 및 오디오 출력 (.wav 파일)을 다운로드 하 고 품질을 위해 후자를 추가로 audition 수 있습니다.

테스트를 위해 선택한 각 모델의 세부 정보 페이지에서 테스트 결과를 찾을 수도 있습니다. **학습** 탭으로 이동 하 고 모델 이름을 클릭 하 여 모델 세부 정보 페이지로 이동 합니다.

## <a name="create-and-use-a-custom-voice-endpoint"></a>사용자 지정 음성 엔드포인트 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 엔드포인트은 글꼴을 배포 하는 데 사용한 구독에 의해서만 호출 될 수 있습니다.

새 사용자 지정 음성 엔드포인트을 만들려면 **텍스트 음성 변환 > 사용자 지정 음성 > 배포**로 이동 합니다. **엔드포인트 추가** 를 선택 하 고 사용자 지정 엔드포인트에 대 한 **이름** 및 **설명** 을 입력 합니다. 그런 다음이 엔드포인트과 연결할 사용자 지정 음성 모델을 선택 합니다.

**추가** 단추를 클릭 하면 엔드포인트 테이블에 새 엔드포인트에 대 한 항목이 표시 됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공**이면 엔드포인트를 사용할 준비가 완료된 것입니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 하나의 모델만 배포할 수 있습니다. 표준 구독 (S0) 사용자는 각각 고유한 사용자 지정 음성을 사용 하 여 최대 50 개의 엔드포인트을 만들 수 있습니다.

> [!NOTE]
> 사용자 지정 음성을 사용 하려면 음성 모델 이름을 지정 하 고, HTTP 요청에서 직접 사용자 지정 URI를 사용 하 고, 동일한 구독을 사용 하 여 TTS 서비스의 인증을 통과 해야 합니다.

엔드포인트이 배포된 후, 엔드포인트 이름이 링크로 표시됩니다. 엔드포인트 키, 엔드포인트 URL 및 샘플 코드와 같은 엔드포인트에 관련된 정보를 표시하려면 링크를 클릭합니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 엔드포인트을 테스트 하려면 엔드포인트 **세부 정보** 페이지에서 **엔드포인트 확인** 을 선택 합니다. 엔드포인트 테스트 페이지가 나타납니다. 텍스트 상자에서 읽을 텍스트 (일반 텍스트 또는 [SSML 형식](speech-synthesis-markup.md) )를 입력 합니다. **재생**을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 이 테스트 기능은 사용자 지정 음성 합성 사용에 대 한 요금이 청구 됩니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [가이드: 음성 샘플 기록](record-custom-voice-samples.md)
* [텍스트 Speech API 참조](rest-text-to-speech.md)
* [긴 오디오 API](long-audio-api.md)
